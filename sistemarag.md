# üìö **Documenta√ß√£o Completa do Sistema RAG Multimodal**

## üîÑ **Fluxo de Ingest√£o de Documentos**

### **1. Google Drive Downloader**
```python
display_name: "Google Drive Downloader"
icon: "üì•"
```

**Fun√ß√£o**: Baixa arquivos do Google Drive convertendo URLs de compartilhamento em downloads diretos.

**Configura√ß√µes**:
- `urls` (lista): URLs do Google Drive (aceita m√∫ltiplos formatos)
- `save_directory` (string): Diret√≥rio para salvar (vazio = retorna base64)
- `timeout` (int): Timeout em segundos (padr√£o: 30)
- `validate_ssl` (bool): Validar certificados SSL (padr√£o: true)
- `silent_errors` (bool): N√£o lan√ßar exce√ß√µes em erros (padr√£o: false)
- `max_file_size` (int): Tamanho m√°ximo em MB (padr√£o: 100)

**Formatos de URL Suportados**:
```
drive.google.com/file/d/[FILE_ID]
drive.google.com/open?id=[FILE_ID] 
docs.google.com/.*[?&]id=[FILE_ID]
```

**Convers√£o de URL**:
```python
# URL original
https://drive.google.com/file/d/1EDArLh4yTTf43UP9ilmeKN02Yyl6rVyQ/view

# URL convertida para download direto
https://drive.google.com/uc?export=download&id=1EDArLh4yTTf43UP9ilmeKN02Yyl6rVyQ
```

**Sa√≠da**:
```json
{
  "filename": "documento.pdf",
  "original_url": "https://drive.google.com/...",
  "direct_url": "https://drive.google.com/uc?...",
  "size": 1024000,
  "size_mb": 1.0,
  "content_base64": "base64_content_here", // se save_directory vazio
  "local_path": "/path/to/file", // se save_directory definido
  "download_success": true
}
```

---

### **2. File Selector**
```python
display_name: "File Selector"
icon: "üîé"
```

**Fun√ß√£o**: Seleciona um arquivo espec√≠fico de uma lista de arquivos baixados.

**Configura√ß√µes**:
- `file_list` (Data): Lista de arquivos do downloader
- `file_index` (int): √çndice do arquivo (0 = primeiro, -1 = √∫ltimo)
- `filename_filter` (string): Filtro por nome (opcional, sobrescreve √≠ndice)

**L√≥gica de Sele√ß√£o**:
1. Remove arquivos com erros
2. Se `filename_filter` definido: busca por substring no nome
3. Se n√£o: usa `file_index`
4. Adiciona metadados de sele√ß√£o

**Sa√≠da**:
```json
{
  // ... dados do arquivo original ...
  "selection_info": {
    "selected_from_count": 3,
    "valid_files_count": 2,
    "selection_method": "filename", // ou "index"
    "selection_criteria": "documento.pdf"
  }
}
```

---

### **3. LlamaParse with Screenshots**
```python
display_name: "LlamaParse with Screenshots"
icon: "üñºÔ∏è"
```

**Fun√ß√£o**: Processa documentos usando LlamaParse com captura de screenshots das p√°ginas.

**API Endpoint**: `https://api.cloud.llamaindex.ai/`

**Configura√ß√µes**:
- `llama_cloud_api_key` (secret): Chave da API LlamaCloud
- `parse_mode` (dropdown): M√©todo de parsing
  - `parse_page_with_llm`
  - `parse_page_without_llm`
  - `parse_page_with_lvm`
  - `parse_page_with_agent` (padr√£o)
  - `parse_page_with_layout_agent`
  - `parse_document_with_llm`
  - `parse_document_with_agent`
- `output_format` (dropdown): Formato de sa√≠da (markdown, text, json)
- `take_screenshot` (bool): Capturar screenshots (padr√£o: true)
- `vendor_multimodal_model` (string): Modelo para LVM (padr√£o: "openai-gpt4o")
- `max_wait_time` (int): Tempo m√°ximo de espera (padr√£o: 300s)
- `poll_interval` (int): Intervalo de polling (padr√£o: 5s)

**Processo de Upload**:
```python
# 1. Upload do arquivo
POST /api/v1/parsing/upload
Headers: {
  "Authorization": "Bearer {api_key}",
  "Content-Type": "multipart/form-data"
}
Data: {
  "file": arquivo_binario,
  "parse_mode": "parse_page_with_agent",
  "take_screenshot": "true",
  "save_images": "false"  # Cr√≠tico: desabilita extra√ß√£o de imagens
}
```

**Processo de Polling**:
```python
# 2. Verificar status
GET /api/v1/parsing/job/{job_id}
# Repete at√© status = "SUCCESS"
```

**Obten√ß√£o de Resultados**:
```python
# 3. Baixar conte√∫do parseado
GET /api/v1/parsing/job/{job_id}/result/{format}

# 4. Baixar screenshots
GET /api/v1/parsing/job/{job_id}/result/image/{image_name}
```

**Sa√≠da Parsed Document**:
```json
{
  "job_id": "abc123",
  "filename": "documento.pdf", 
  "output_format": "markdown",
  "parse_mode": "parse_page_with_agent",
  "success": true,
  "markdown_content": "# T√≠tulo\n\nConte√∫do...",
  "char_count": 5000,
  "screenshots_available": true,
  "screenshots_count": 5
}
```

**Sa√≠da Screenshots**:
```json
{
  "screenshots": [
    {
      "page": 1,
      "filename": "page_1.jpg",
      "content_base64": "data:image/jpeg;base64,/9j/4AAQ...",
      "size": 156789,
      "content_type": "image/jpeg",
      "image_type": "screenshot"
    }
  ],
  "total_screenshots": 5,
  "job_id": "abc123",
  "success": true
}
```

---

### **4. LlamaParse Multimodal Merger**
```python
display_name: "LlamaParse Multimodal Merger"
icon: "üß©"
```

**Fun√ß√£o**: Combina conte√∫do markdown do LlamaParse com screenshots em chunks multimodais estruturados.

**Configura√ß√µes**:
- `merge_strategy` (dropdown): Estrat√©gia de combina√ß√£o
  - `page_based` (padr√£o): Um chunk por p√°gina
  - `section_based`: Chunks por cabe√ßalhos
  - `smart_chunks`: Divis√£o inteligente de texto
  - `text_only`: S√≥ texto, sem imagens
  - `image_only`: S√≥ imagens, sem texto
- `max_chunk_size` (int): M√°ximo de caracteres por chunk (padr√£o: 1500)
- `include_metadata` (bool): Incluir metadados de parsing (padr√£o: true)
- `document_name` (string): Nome do documento (auto-detectado se vazio)
- `preserve_page_structure` (bool): Manter organiza√ß√£o original (padr√£o: true)

**Estrat√©gias de Merge**:

1. **Page-based** (mais comum):
```python
def _merge_by_page():
    # Divide markdown por p√°ginas (---) ou igualmente
    # Associa cada p√°gina com seu screenshot correspondente
    # Cria chunk_id = "{doc_name}_page_{num}"
```

2. **Section-based**:
```python
def _split_markdown_by_headers():
    # Divide por cabe√ßalhos (# ##)
    # Estima p√°gina baseada na posi√ß√£o no texto
```

3. **Smart chunking**:
```python
def _split_text_smart():
    # Respeita max_chunk_size
    # Quebra por par√°grafos, depois por senten√ßas
    # Distribui screenshots proporcionalmente
```

**Extra√ß√£o de Document Name**:
```python
# Prioridade:
1. document_name manual
2. metadata.jobInfo.fileName
3. filename do arquivo
4. "Document_{job_id[:8]}"
```

**Sa√≠da**:
```json
{
  "chunks": [
    {
      "chunk_id": "documento_page_1",
      "content": "# T√≠tulo\n\nConte√∫do da p√°gina 1...",
      "content_type": "multimodal",
      "page_number": 1,
      "document_name": "documento",
      "char_count": 856,
      "image_base64": "data:image/jpeg;base64,...",
      "image_filename": "page_1.jpg",
      "image_size": 156789,
      "source": "llamaparse",
      "merge_strategy": "page_based",
      "metadata": {
        "document_name": "documento",  // GARANTIDO aqui
        "parse_mode": "parse_page_with_agent",
        "job_id": "abc123"
      }
    }
  ],
  "total_chunks": 5,
  "multimodal_chunks": 5,
  "text_only_chunks": 0,
  "document_name": "documento"
}
```

---

## üß¨ **Sistema de Embeddings**

### **5. Voyage Multimodal Embedder**
```python
display_name: "Voyage Multimodal Embedder"
icon: "üß¨" / "‚ö°"
```

**Fun√ß√£o**: Gera embeddings multimodais usando a API da Voyage AI.

**API Endpoint**: `https://api.voyageai.com/v1/multimodalembeddings`

**Configura√ß√µes**:
- `voyage_api_key` (secret): Chave da API Voyage AI
- `mode` (dropdown): Tipo de embedding
  - `chunks`: Para documentos (input_type="document")
  - `query`: Para consultas de busca (input_type="query")
- `query_text` (string): Texto da consulta (apenas no modo query)

**Chamada da API**:
```python
POST https://api.voyageai.com/v1/multimodalembeddings
Headers: {
  "Authorization": "Bearer {voyage_api_key}",
  "Content-Type": "application/json"
}

Payload: {
  "inputs": [
    {
      "content": [
        {
          "type": "text",
          "text": "Conte√∫do do texto aqui..."
        },
        {
          "type": "image_base64", 
          "image_base64": "data:image/jpeg;base64,..."
        }
      ]
    }
  ],
  "model": "voyage-multimodal-3",
  "input_type": "document", // ou "query"
  "truncation": true
}
```

**Processamento em Lotes**:
- Lotes de 10 chunks (conservador para evitar timeouts)
- Limita texto a 5000 caracteres (~1000 tokens)
- Suporta formatos: image/png, image/jpeg, image/webp, image/gif

**Extra√ß√£o de Conte√∫do**:
```python
def _extract_text(chunk):
    # Prioridade: content -> markdown_content -> text
    
def _extract_image(chunk):
    # Prioridade: image_base64 -> image_data
    # Converte para formato correto se necess√°rio
    # Adiciona header data:image/jpeg se for base64 puro
```

**Resposta da API**:
```json
{
  "data": [
    {
      "object": "embedding",
      "embedding": [0.1, -0.2, 0.3, ...], // 1024 dimens√µes
      "index": 0
    }
  ],
  "model": "voyage-multimodal-3",
  "usage": {
    "total_tokens": 150
  }
}
```

**Sa√≠da - Modo Query**:
```json
{
  "query": "texto da consulta",
  "embedding": [0.1, -0.2, 0.3, ...],
  "dimension": 1024,
  "model": "voyage-multimodal-3",
  "type": "query"
}
```

**Sa√≠da - Modo Chunks**:
```json
{
  "chunks": [
    {
      // ... dados originais do chunk ...
      "embedding": [0.1, -0.2, 0.3, ...],
      "dimension": 1024,
      "model": "voyage-multimodal-3"
    }
  ],
  "total_chunks": 5,
  "model": "voyage-multimodal-3",
  "type": "chunks"
}
```

---

## ‚òÅÔ∏è **Sistema de Storage**

### **6. Cloudflare R2 Image Uploader**
```python
display_name: "Cloudflare R2 Image Uploader"
icon: "‚òÅÔ∏è"
```

**Fun√ß√£o**: Faz upload de imagens base64 para Cloudflare R2 e substitui por URLs p√∫blicas.

**Configura√ß√µes**:
- `r2_endpoint` (string): Endpoint da API R2 (ex: https://agenciawow.ilceccato88.workers.dev)
- `auth_token` (secret): Token de autentica√ß√£o Bearer
- `image_field` (string): Campo com imagem base64 (padr√£o: "image_base64")
- `filename_field` (string): Campo com nome do arquivo (padr√£o: "image_filename")
- `doc_source_field` (string): Campo para gerar prefixos √∫nicos (padr√£o: "document_name")
- `replace_existing` (bool): Deletar imagens existentes antes (padr√£o: true)
- `keep_original_base64` (bool): Manter base64 original (padr√£o: false)

**Processo de Upload**:

1. **Extra√ß√£o de Document Name**:
```python
def _get_document_name():
    # Tenta extrair de chunks[0].document_name
    # ou chunks[0].metadata.document_name
    # Remove extens√£o de arquivo
    # Limpa caracteres especiais (permite acentos)
```

2. **Dele√ß√£o de Existentes** (se `replace_existing=true`):
```python
DELETE {r2_endpoint}/delete-doc/{document_name}
Headers: {"Authorization": "Bearer {auth_token}"}
```

3. **Upload Individual**:
```python
PUT {r2_endpoint}/upload/{unique_filename}
Headers: {
  "Authorization": "Bearer {auth_token}",
  "Content-Type": "application/octet-stream"
}
Body: image_bytes

# unique_filename = "{document_name}_page_{num}_{original_filename}"
```

4. **Gera√ß√£o de URL P√∫blica**:
```python
public_url = f"{r2_endpoint}/file/{unique_filename}"
```

**Sa√≠da**:
```json
{
  "documents": [
    {
      // ... dados originais sem image_base64 ...
      "image_url": "https://agenciawow.ilceccato88.workers.dev/file/documento_page_1_page_1.jpg",
      "image_filename_r2": "documento_page_1_page_1.jpg", 
      "image_size_original": 250000, // tamanho base64
      "image_size_bytes": 156789,    // tamanho imagem
      "document_name_used": "documento",
      "prefix_used": "documento"
    }
  ],
  "status": "completed",
  "summary": {
    "total_documents": 5,
    "total_images_found": 5,
    "total_images_uploaded": 5,
    "success_rate": "100.0%",
    "r2_endpoint": "https://agenciawow.ilceccato88.workers.dev"
  }
}
```

---

### **7. Astra DB Optimized Inserter**
```python
display_name: "Astra DB Optimized Inserter"
icon: "üóÑÔ∏è"
```

**Fun√ß√£o**: Insere documentos no Astra DB com otimiza√ß√µes para evitar limites de tamanho.

**API Endpoint**: `{api_endpoint}/api/json/v1/{keyspace}/{collection}`

**Configura√ß√µes**:
- `api_endpoint` (string): Endpoint base do Astra DB
- `auth_token` (secret): Token de aplica√ß√£o Astra (AstraCS...)
- `keyspace` (string): Nome do keyspace (padr√£o: "default_keyspace")
- `collection_name` (string): Nome da cole√ß√£o
- `replace_existing` (bool): Substituir documentos existentes (padr√£o: true)
- `content_field` (string): Campo com conte√∫do principal (padr√£o: "content")
- `embedding_field` (string): Campo com vetor embedding (padr√£o: "embedding")
- `doc_source_field` (string): Campo para identificar documento (padr√£o: "document_name")
- `batch_size` (int): Documentos por lote (padr√£o: 50, m√°x: 100)
- `max_text_length` (int): Tamanho m√°ximo de campos texto (padr√£o: 7000)

**Otimiza√ß√µes Implementadas**:

1. **Limpeza de Base64**:
```python
def _clean_base64_from_dict(data):
    # Remove TODOS os campos *base64* recursivamente
    # Evita problemas de tamanho no Astra DB
```

2. **Truncamento de Texto**:
```python
def _truncate_text_field(text, max_length):
    if len(text) > max_length:
        return text[:max_length-3] + "..."
```

3. **Estrutura Otimizada**:
```python
astra_doc = {
    "_id": chunk_id,
    "content": truncated_content,
    "$vector": embedding_array,
    "document_name": doc_name,
    "page_number": page_num,
    "image_url": url,  // URL em vez de base64
    "image_filename_r2": filename,
    "metadata": {
        "document_name": doc_name,  // Garantido aqui tamb√©m
        // outros campos menores
    }
}
```

**Processo de Substitui√ß√£o**:
```python
# Se replace_existing=true
DELETE_FILTERS = [
    {"document_name": source},
    {"metadata.document_name": source}
]

for filter in DELETE_FILTERS:
    payload = {"deleteMany": {"filter": filter}}
    POST {astra_endpoint}
```

**Inser√ß√£o em Lotes**:
```python
payload = {
    "insertMany": {
        "documents": batch  // at√© 100 docs
    }
}
POST {astra_endpoint}
```

**Sa√≠da**:
```json
{
  "status": "completed",
  "insertion_result": {
    "inserted_count": 5,
    "inserted_ids": ["doc_1", "doc_2", ...],
    "total_batches": 1
  },
  "replacement_result": {
    "total_deleted": 3,
    "sources_processed": ["documento"]
  },
  "summary": {
    "total_documents_prepared": 5,
    "total_documents_inserted": 5,
    "success_rate": "100.0%",
    "total_data_size_kb": 45.2,
    "uses_image_urls": true,
    "optimization": "enabled"
  }
}
```

---

## üîç **Sistema de Busca e Recupera√ß√£o**

### **8. Chat Input**
```python
display_name: "Chat Input"
icon: "MessagesSquare"
```

**Fun√ß√£o**: Captura input do usu√°rio no Playground.

**Configura√ß√µes**:
- `input_value` (multiline): Texto da mensagem
- `should_store_message` (bool): Armazenar no hist√≥rico (padr√£o: true)
- `sender` (dropdown): Tipo de remetente (Machine/User)
- `sender_name` (string): Nome do remetente
- `session_id` (string): ID da sess√£o
- `files` (file): Arquivos anexos (imagens, documentos)

**Sa√≠das**:
- `message`: Objeto Message com o texto
- `session_id_output`: Session ID como Message

---

### **9. Multimodal Document Searcher**
```python
display_name: "Multimodal Document Searcher"
icon: "üîç"
```

**Fun√ß√£o**: Busca vetorial no Astra DB otimizada para conte√∫do multimodal.

**Configura√ß√µes**:
- `query_text` (string): Consulta de busca
- `query_embedding` (Data): Embedding da consulta (do Voyage AI)
- `limit` (int): N√∫mero de resultados (padr√£o: 3, recomendado: 3-5)
- `similarity_threshold` (float): Limite de similaridade (0.0 = sem filtro)
- `include_images` (bool): Incluir campo image_base64 (padr√£o: true)
- `timeout` (int): Timeout da requisi√ß√£o (padr√£o: 30s)

**Busca Vetorial**:
```python
payload = {
    "find": {
        "sort": {"$vector": embedding_vector},
        "options": {
            "limit": limit,
            "includeSimilarity": true
        },
        "projection": {
            "$vector": false,  // N√£o retornar o vetor
            "_id": true,
            "content": true,
            "document_name": true,
            "page_number": true,
            "image_url": true,           // SEMPRE inclu√≠do
            "image_filename_r2": true,   // SEMPRE inclu√≠do
            "image_base64": include_images,
            "metadata": true
        }
    }
}
```

**Filtro por Similaridade**:
```python
if similarity_threshold > 0.0:
    filtered_docs = [doc for doc in documents 
                    if doc.get("$similarity", 0.0) >= similarity_threshold]
```

**Sa√≠da**:
```json
{
  "documents": [
    {
      "_id": "documento_page_1",
      "content": "Conte√∫do da p√°gina...",
      "document_name": "documento",
      "page_number": 1,
      "similarity": 0.892,
      "image_url": "https://agenciawow.ilceccato88.workers.dev/file/documento_page_1.jpg",
      "image_filename_r2": "documento_page_1.jpg",
      "has_image": false,  // ser√° true ap√≥s download
      "metadata": {"document_name": "documento"}
    }
  ],
  "total_results": 3,
  "similarity_stats": {
    "min_similarity": 0.756,
    "max_similarity": 0.892,
    "avg_similarity": 0.824
  },
  "query_text": "consulta do usu√°rio"
}
```

---

### **10. R2 Image Downloader**
```python
display_name: "R2 Image Downloader" 
icon: "üñºÔ∏è"
```

**Fun√ß√£o**: Baixa imagens dos URLs do R2 e converte para base64 para o reranker.

**Configura√ß√µes**:
- `auth_token` (secret): Token de autentica√ß√£o R2
- `max_images` (int): Limite de imagens a baixar (0 = todas)

**Processo de Download**:
```python
for doc in documents:
    image_url = doc.get("image_url")
    if image_url:
        headers = {"Authorization": f"Bearer {auth_token}"}
        response = requests.get(image_url, headers=headers)
        
        # Detecta tipo da imagem
        img_type = imghdr.what(None, response.content) or "jpeg"
        
        # Converte para base64 com header
        b64 = base64.b64encode(response.content).decode("utf-8")
        doc["image_base64"] = f"data:image/{img_type};base64,{b64}"
        doc["has_image"] = True
```

**Sa√≠da**:
```json
{
  "documents": [
    {
      // ... dados originais ...
      "image_base64": "data:image/jpeg;base64,/9j/4AAQ...",
      "has_image": true
    }
  ],
  "total_documents": 3,
  "images_downloaded": 3
}
```

---

## üéØ **Sistema de Reranking**

### **11. GPT Multimodal Reranker**
```python
display_name: "GPT Multimodal Reranker"
icon: "‚ú®"
```

**Fun√ß√£o**: Usa GPT-4o para selecionar os documentos mais relevantes analisando texto E imagens.

**API**: OpenAI Chat Completions

**Configura√ß√µes**:
- `openai_api_key` (secret): Chave da API OpenAI
- `model_name` (dropdown): Modelo GPT
  - `gpt-4o` (recomendado para multimodal)
  - `gpt-4o-mini` (padr√£o, mais barato)
  - `gpt-4.1`, `gpt-4.1-mini`
- `max_return` (int): M√°ximo de documentos a selecionar (padr√£o: 2)
- `temperature` (float): Temperatura da resposta (padr√£o: 0.0)
- `max_tokens` (int): Tokens m√°ximos da resposta (padr√£o: 500)
- `text_preview_length` (int): Caracteres de texto por documento (padr√£o: 700)

**Verifica√ß√£o de Suporte Multimodal**:
```python
multimodal_models = ["gpt-4o", "gpt-4o-mini", "gpt-4.1", "gpt-4.1-mini"]
supports_images = model_name in multimodal_models
```

**Constru√ß√£o do Prompt**:
```python
content = [
    {
        "type": "text", 
        "text": f"""Pergunta do usu√°rio: "{query}"
        Foram selecionados {len(docs)} documentos relevantes.
        Selecione no m√°ximo {max_return} para responder √† pergunta.
        
        Formato esperado:
        Documentos_Selecionados: [√≠ndices]
        Justificativa: ..."""
    }
]

for i, doc in enumerate(docs):
    # Adiciona texto truncado
    text = f"\n=== [{i}] {doc_name} - P√°gina {page} (score: {similarity:.3f}) ===\n{content[:700]}..."
    content.append({"type": "text", "text": text})
    
    # Adiciona imagem se suportado
    if image_base64 and supports_images:
        content.append({
            "type": "image_url",
            "image_url": {"url": image_base64}
        })
```

**Chamada da API**:
```python
response = client.chat.completions.create(
    model=model_name,
    messages=[{"role": "user", "content": content}],
    max_tokens=max_tokens,
    temperature=temperature,
)
```

**Parse da Resposta**:
```python
result = response.choices[0].message.content

# Extrai √≠ndices e justificativa
for line in result.splitlines():
    if "Documentos_Selecionados" in line:
        indices = [int(n) for n in re.findall(r"\d+", line)]
    elif "Justificativa" in line:
        justification = line.split(":", 1)[-1].strip()

selected_docs = [docs[i] for i in valid_indices]
```

**Sa√≠da**:
```json
{
  "selected_docs": [
    {
      // documento 1 selecionado
    },
    {
      // documento 2 selecionado  
    }
  ],
  "justification": "Os documentos 0 e 2 s√£o mais relevantes pois...",
  "indices": [0, 2],
  "total_candidates": 5,
  "model": "gpt-4o-mini",
  "query": "consulta do usu√°rio",
  "config": {
    "supports_multimodal": true,
    "processing_time": 2.34
  }
}
```

---

### **12. Reranker Parser**
```python
display_name: "Reranker Parser"
icon: "üîç"
```

**Fun√ß√£o**: Extrai e formata o conte√∫do selecionado pelo reranker para o agente final.

**Configura√ß√µes**:
- `output_mode` (dropdown): Tipo de sa√≠da
  - `All`: Textos e imagens
  - `Texts Only`: Apenas textos
  - `Images Only`: Apenas imagens

**M√∫ltiplas Sa√≠das**:

1. **Texts** (`extract_texts`):
```json
{
  "texts": [
    "**Documento: documento (P√°gina 1)**\n\nConte√∫do da p√°gina 1...",
    "**Documento: documento (P√°gina 3)**\n\nConte√∫do da p√°gina 3..."
  ],
  "count": 2
}
```

2. **Images** (`extract_images`):
```json
{
  "images": [
    {
      "image": "data:image/jpeg;base64,...",
      "document_name": "documento",
      "page_number": 1,
      "type": "base64"
    }
  ],
  "count": 1
}
```

3. **Metadata** (`extract_metadata`):
```json
{
  "metadata": [
    {
      "index": 0,
      "document_name": "documento",
      "page_number": 1,
      "similarity": 0.892,
      "has_image": true,
      "content_length": 856
    }
  ],
  "summary": {
    "total_docs": 2,
    "with_images": 1,
    "avg_similarity": 0.834
  }
}
```

4. **Combined Content** (`extract_combined`):
```json
{
  "combined_content": [
    {
      "index": 0,
      "document_name": "documento",
      "page_number": 1,
      "text": "Conte√∫do da p√°gina...",
      "has_image": true,
      "image": "data:image/jpeg;base64,...",
      "image_type": "base64",
      "similarity": 0.892,
      "formatted_text": "üìÑ **documento - P√°gina 1** (Similaridade: 0.892)\n\nConte√∫do da p√°gina..."
    }
  ],
  "count": 2,
  "total_text_length": 1712,
  "images_count": 1
}

## ü§ñ **Sistema de Resposta Final**

### **13. Enhanced Agent (Multimodal RAG)**
```python
display_name: "Enhanced Agent (Multimodal RAG)"
icon: "ü§ñ"
```

**Fun√ß√£o**: Agente conversacional avan√ßado com capacidades multimodais e integra√ß√£o RAG completa.

**Configura√ß√µes do Modelo**:
- `agent_llm` (dropdown): Provedor do modelo
  - OpenAI, Anthropic, Azure OpenAI, Google Generative AI, Groq, NVIDIA, SambaNova, Custom
- `model_name` (dropdown): Modelo espec√≠fico
  - `gpt-4o-mini` (padr√£o)
  - `gpt-4o`, `gpt-4.5-preview`, `gpt-4-turbo`, etc.
- `api_key` (secret): Chave da API OpenAI
- `openai_api_base` (string): URL base customizada (opcional)
- `temperature` (slider): Criatividade (padr√£o: 0.1)
- `max_tokens` (int): Tokens m√°ximos (0 = ilimitado)
- `max_retries` (int): Tentativas m√°ximas (padr√£o: 5)
- `timeout` (int): Timeout em segundos (padr√£o: 700)

**Configura√ß√µes Multimodais**:
- `multimodal_context` (Data): Conte√∫do do Reranker Parser
- `enable_multimodal` (bool): Ativar processamento multimodal (padr√£o: true)

**Configura√ß√µes do Agente**:
- `system_prompt` (multiline): Instru√ß√µes do sistema
- `tools` (list): Ferramentas dispon√≠veis
- `handle_parsing_errors` (bool): Corrigir erros de parsing (padr√£o: true)
- `verbose` (bool): Log detalhado (padr√£o: true)
- `max_iterations` (int): Itera√ß√µes m√°ximas (padr√£o: 15)

**System Prompt Padr√£o**:
```text
You are a helpful assistant that can use tools to answer questions and perform tasks. If multimodal content is provided, analyze both text and images to provide comprehensive responses.

IMPORTANTE: NUNCA use formata√ß√£o Markdown como **, _, #, ###, -, * ou outros s√≠mbolos de formata√ß√£o. 
Escreva sempre em texto corrido, natural e conversacional.
Use apenas texto simples, v√≠rgulas, pontos e quebras de linha quando necess√°rio.
Seja direto, claro e natural na linguagem.
```

**Verifica√ß√£o de Suporte Multimodal**:
```python
def _check_multimodal_support():
    if agent_llm == "OpenAI":
        multimodal_models = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-vision-preview', 'gpt-4-turbo']
        return any(mm in model_name for mm in multimodal_models)
    elif agent_llm == "Anthropic":
        return 'claude-3' in model_name or 'claude-3.5' in model_name
    return False
```

**Processamento do Contexto Multimodal**:

1. **Extra√ß√£o de Conte√∫do**:
```python
def _extract_multimodal_content():
    data = multimodal_context.value
    
    # Tenta diferentes formatos
    if "combined_content" in data:
        return data["combined_content"]
    elif "formatted_content" in data:
        return data["formatted_content"] 
    elif "documents" in data:
        return data["documents"]
    
    return []
```

2. **Prepara√ß√£o do System Prompt**:
```python
def _prepare_multimodal_system_prompt(multimodal_content):
    context_info = []
    for item in multimodal_content:
        info = f"- {doc_name}"
        if page_num:
            info += f" (P√°gina {page_num})"
        if has_image:
            info += " [Com imagem]"
        context_info.append(info)
    
    multimodal_addition = f"""
    
CONTEXTO MULTIMODAL DISPON√çVEL:
{chr(10).join(context_info)}

Instru√ß√µes adicionais:
- Use tanto o texto quanto as imagens fornecidas para responder
- Quando relevante, cite as p√°ginas espec√≠ficas dos documentos  
- Se houver discrep√¢ncias entre texto e imagem, mencione
- Seja preciso e espec√≠fico baseado no conte√∫do fornecido
- NUNCA use formata√ß√£o Markdown (**, _, #, ###, -, *, etc.)
- Escreva sempre em texto corrido, natural e conversacional
"""
    
    return base_prompt + multimodal_addition
```

3. **Inje√ß√£o no Input do Usu√°rio**:
```python
def _inject_multimodal_into_input(multimodal_content):
    context_parts = ["=== CONTEXTO MULTIMODAL ==="]
    
    for item in multimodal_content:
        part = f"\nDocumento: {doc_name}"
        if page_num:
            part += f" - P√°gina {page_num}"
        if has_image:
            part += " (com imagem)"
        part += f"\nConte√∫do: {text}\n"
        context_parts.append(part)
    
    context_parts.append("=== FIM DO CONTEXTO ===")
    context_parts.append(f"Pergunta do usu√°rio: {input_value}")
    
    return "\n".join(context_parts)
```

**Ferramentas Autom√°ticas**:
- `add_current_date_tool` (bool): Adiciona ferramenta de data atual (padr√£o: true)

**Configura√ß√µes de Mem√≥ria**:
- `memory` (Memory): Mem√≥ria externa (opcional)
- `sender` (dropdown): Tipo de remetente para hist√≥rico
- `sender_name` (string): Nome do remetente
- `n_messages` (int): N√∫mero de mensagens no hist√≥rico (padr√£o: 100)
- `session_id` (string): ID da sess√£o
- `order` (dropdown): Ordem das mensagens (Ascending/Descending)
- `template` (string): Template de formata√ß√£o: "{sender_name}: {text}"

**Processo de Execu√ß√£o**:
```python
async def message_response():
    # 1. Validar e obter modelo LLM
    llm_model = get_llm()
    
    # 2. Obter hist√≥rico de mem√≥ria
    chat_history = await get_memory_data()
    
    # 3. Extrair conte√∫do multimodal
    multimodal_content = _extract_multimodal_content()
    
    # 4. Verificar suporte multimodal
    supports_multimodal = _check_multimodal_support()
    
    # 5. Adicionar ferramenta de data se habilitada
    if add_current_date_tool:
        tools.append(current_date_tool)
    
    # 6. Preparar prompts com contexto multimodal
    enhanced_system_prompt = _prepare_multimodal_system_prompt(multimodal_content)
    enhanced_input = _inject_multimodal_into_input(multimodal_content)
    
    # 7. Configurar e executar agente
    agent = create_agent_runnable()
    return await run_agent(agent)
```

**Sa√≠da**:
```json
Message(
    text="Baseado no documento analisado, posso ver na p√°gina 1 que...",
    sender="Machine",
    sender_name="AI", 
    session_id="123456",
    flow_id="flow_id"
)
```

---

### **14. Chat Output**
```python
display_name: "Chat Output"
icon: "MessagesSquare"
```

**Fun√ß√£o**: Exibe a resposta final no Playground e armazena no hist√≥rico.

**Configura√ß√µes**:
- `input_value` (Message/Data): Resposta do agente
- `should_store_message` (bool): Armazenar no hist√≥rico (padr√£o: true)
- `sender` (dropdown): Tipo de remetente (Machine/User)
- `sender_name` (string): Nome do remetente (padr√£o: "AI")
- `session_id` (string): ID da sess√£o
- `data_template` (string): Template para convers√£o (padr√£o: "{text}")
- `clean_data` (bool): Limpeza b√°sica dos dados (padr√£o: true)

**Processo**:
1. Converte entrada para string se necess√°rio
2. Cria ou atualiza objeto Message
3. Define propriedades (sender, session_id, etc.)
4. Armazena na mem√≥ria se configurado
5. Retorna Message para exibi√ß√£o

---

## üß† **Sistema de Mem√≥ria**

### **15. Message History**
```python
display_name: "Message History"
icon: "message-square-more"
```

**Fun√ß√£o**: Recupera hist√≥rico de mensagens das tabelas Langflow ou mem√≥ria externa.

**Configura√ß√µes**:
- `memory` (Memory): Mem√≥ria externa (opcional)
- `sender` (dropdown): Filtro por remetente
  - "Machine", "User", "Machine and User" (padr√£o)
- `sender_name` (string): Filtro por nome do remetente
- `n_messages` (int): N√∫mero de mensagens (padr√£o: 100)
- `session_id` (string): ID da sess√£o
- `order` (dropdown): Ordem (Ascending/Descending)
- `template` (string): Template de formata√ß√£o

**Sa√≠das**:
- `messages` (Data): Lista de objetos Message
- `messages_text` (Message): Texto formatado do hist√≥rico  
- `dataframe` (DataFrame): Hist√≥rico como DataFrame

---

### **16. Astra DB Chat Memory**
```python
display_name: "Astra DB Chat Memory"
icon: "AstraDB"
```

**Fun√ß√£o**: Mem√≥ria persistente usando Astra DB para armazenar hist√≥rico de conversas.

**Configura√ß√µes**:
- `token` (secret): Token de aplica√ß√£o Astra DB
- `api_endpoint` (secret): Endpoint da API Astra
- `collection_name` (string): Nome da cole√ß√£o (padr√£o: "chat_history")
- `namespace` (string): Namespace opcional
- `session_id` (string): ID da sess√£o

**Implementa√ß√£o**:
```python
from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory

return AstraDBChatMessageHistory(
    session_id=session_id,
    collection_name=collection_name,
    token=token,
    api_endpoint=api_endpoint,
    namespace=namespace or None,
    environment=parse_api_endpoint(api_endpoint).environment,
)
```

---

### **17. Message Store (√ó2)**
```python
display_name: "Message Store"
icon: "message-square-text"
```

**Fun√ß√£o**: Armazena mensagens nas tabelas Langflow ou mem√≥ria externa.

**Configura√ß√µes**:
- `message` (string): Mensagem a ser armazenada
- `memory` (Memory): Mem√≥ria externa (opcional)
- `sender` (string): Remetente (Machine/User)
- `sender_name` (string): Nome do remetente
- `session_id` (string): ID da sess√£o

**Dois Instances**:
1. **StoreMessage-RT1Cy**: Armazena respostas da IA (sender="AI")
2. **StoreMessage-tgzfN**: Armazena mensagens do usu√°rio (sender="User")

---

### **18. Prompt**
```python
display_name: "Prompt"
icon: "prompts"
```

**Fun√ß√£o**: Cria template de prompt com vari√°veis din√¢micas.

**Template Configurado**:
```text
You are a helpful assistant that can use tools to answer questions and perform tasks.

FORMATA√á√ÉO: N√£o use Markdown (**, #, etc.). Escreva em texto corrido natural.

MULTIMODAL: Se conte√∫do multimodal for fornecido, analise tanto texto quanto imagens para responder de forma completa.

Hist√≥rico da ultimas mensagens em ordem ascendente:

{history}
```

**Vari√°veis**:
- `history` (string): Hist√≥rico formatado do Memory component

---

## üóëÔ∏è **Componentes de Administra√ß√£o**

### **19. Astra Document Deleter**
```python
display_name: "Astra Document Deleter"
icon: "üóëÔ∏è"
```

**Fun√ß√£o**: Deleta documentos do Astra DB por nome de origem ou limpa cole√ß√£o inteira.

**Configura√ß√µes**:
- `deletion_mode` (dropdown):
  - `delete_by_source`: Deletar por prefixo de documento
  - `delete_all_collection`: Deletar toda a cole√ß√£o
- `doc_source_name` (string): Nome do documento para deletar
- `doc_source_field` (string): Campo identificador (padr√£o: "document_name")
- `try_multiple_locations` (bool): Buscar em campos diretos e metadata (padr√£o: true)
- `delete_all_batches` (bool): Continuar at√© deletar tudo (padr√£o: true)
- `max_batches` (int): M√°ximo de lotes (padr√£o: 100)
- `dry_run` (bool): Simular sem deletar (padr√£o: false)
- `confirm_delete_all` (bool): **OBRIGAT√ìRIO** para delete_all_collection

**Filtros Tentados** (se `try_multiple_locations=true`):
```python
filter_options = [
    {"document_name": source_name},
    {"metadata.document_name": source_name},
    {"source": source_name},
    {"doc_source": source_name},
    {"file_name": source_name},
    {"filename": source_name},
    {"metadata.source": source_name},
    {"metadata.doc_source": source_name},
    {"metadata.file_name": source_name},
    {"metadata.filename": source_name},
    {"_id": {"$regex": f"^{source_name}_"}}
]
```

**API Calls**:
```python
# Contar documentos (dry run)
payload = {"countDocuments": {"filter": filter_criteria}}

# Deletar em lotes
payload = {"deleteMany": {"filter": filter_criteria}}
```

---

### **20. Cloudflare R2 Document Deleter**
```python
display_name: "Cloudflare R2 Document Deleter"
icon: "üóëÔ∏è"
```

**Fun√ß√£o**: Deleta arquivos do Cloudflare R2 por prefixo de documento ou todos os arquivos.

**Configura√ß√µes**:
- `r2_endpoint` (string): Endpoint da API R2
- `auth_token` (secret): Token de autentica√ß√£o
- `deletion_mode` (dropdown):
  - `delete_by_prefix`: Deletar por prefixo
  - `delete_all_files`: Deletar todos os arquivos
- `document_prefix` (string): Prefixo para deletar
- `dry_run` (bool): Simular sem deletar
- `confirm_delete_all` (bool): **OBRIGAT√ìRIO** para delete_all_files
- `timeout` (int): Timeout em segundos (padr√£o: 60)

**Endpoints da API R2**:
```python
# Listar arquivos por prefixo
GET {r2_endpoint}/list/{prefix}

# Obter estat√≠sticas do bucket
GET {r2_endpoint}/stats

# Deletar por prefixo
DELETE {r2_endpoint}/delete-doc/{prefix}

# Deletar todos os arquivos
DELETE {r2_endpoint}/delete-all
```

---

## üîß **Configura√ß√µes Globais e Conex√µes**

### **Environment Variables / Secrets**
```bash
# APIs Externas
OPENAI_API_KEY=sk-...
VOYAGE_API_KEY=va-...
LLAMA_CLOUD_API_KEY=llx_...

# Astra DB
ASTRA_DB_APPLICATION_TOKEN=AstraCS:...
ASTRA_DB_API_ENDPOINT=https://database-id-region.apps.astra.datastax.com

# Cloudflare R2
R2_ENDPOINT=https://agenciawow.ilceccato88.workers.dev
R2_AUTH_TOKEN=supersecreto123
```

### **Fluxo de Dados Principal**
```mermaid
graph TD
    A[Google Drive] --> B[File Selector]
    B --> C[LlamaParse]
    C --> D[Multimodal Merger]
    D --> E[Voyage Embedder]
    E --> F[R2 Uploader]
    F --> G[Astra DB Inserter]
    
    H[User Query] --> I[Voyage Query Embedder]
    I --> J[Astra Searcher]
    J --> K[R2 Image Downloader]
    K --> L[GPT Reranker]
    L --> M[Reranker Parser]
    M --> N[Enhanced Agent]
    N --> O[Chat Output]
    
    P[Memory] --> N
    N --> Q[Store Message]
```

### **Configura√ß√µes de Session**
- **Session ID**: "123456" (configurado em m√∫ltiplos componentes)
- **Keyspace**: "default_keyspace" (Astra DB)
- **Collection**: "agenciawow" (documentos), "chat_history" (conversas)

### **Otimiza√ß√µes Implementadas**
1. **Storage Efficiency**: URLs em vez de base64 no Astra DB
2. **Batch Processing**: Inser√ß√µes e buscas em lotes otimizados  
3. **Error Handling**: Componentes com fallbacks e retry logic
4. **Memory Management**: Limpeza autom√°tica de campos grandes
5. **Multimodal Optimization**: Reranking inteligente com GPT-4o

### **Limita√ß√µes e Considera√ß√µes**
1. **Tamanho de Documentos**: Limitado pelo LlamaParse e Astra DB
2. **Concorr√™ncia**: Session ID √∫nico pode causar conflitos
3. **Custos**: APIs pagas (OpenAI, Voyage, LlamaParse)
4. **Lat√™ncia**: Pipeline complexo pode ser lento
5. **Depend√™ncias**: M√∫ltiplos servi√ßos externos

Este sistema representa um **estado da arte** em RAG multimodal, combinando as melhores tecnologias dispon√≠veis para criar uma experi√™ncia de IA verdadeiramente avan√ßada que pode "ver" e "entender" documentos complexos.